{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqnZEussd6CPui1n1+MP2q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nYeC4AvyGjeS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709620815183,"user_tz":-540,"elapsed":25442,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}},"outputId":"501d3560-cee7-4fbe-fa57-d491ca4ec7d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install open3d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYHqkJkUjufn","executionInfo":{"status":"ok","timestamp":1709620851867,"user_tz":-540,"elapsed":36688,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}},"outputId":"0e370b33-228c-4e99-b4b2-d98208aed8cb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting open3d\n","  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.25.2)\n","Collecting dash>=2.6.0 (from open3d)\n","  Downloading dash-2.16.0-py3-none-any.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n","Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n","Collecting configargparse (from open3d)\n","  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n","Collecting ipywidgets>=8.0.4 (from open3d)\n","  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict (from open3d)\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n","Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.2)\n","Collecting pyquaternion (from open3d)\n","  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n","Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n","Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n","Collecting retrying (from dash>=2.6.0->open3d)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n","Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n","  Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n","Collecting widgetsnbextension~=4.0.10 (from ipywidgets>=8.0.4->open3d)\n","  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n","Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.18.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.2.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n","Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n","  Attempting uninstall: widgetsnbextension\n","    Found existing installation: widgetsnbextension 3.6.6\n","    Uninstalling widgetsnbextension-3.6.6:\n","      Successfully uninstalled widgetsnbextension-3.6.6\n","  Attempting uninstall: ipywidgets\n","    Found existing installation: ipywidgets 7.7.1\n","    Uninstalling ipywidgets-7.7.1:\n","      Successfully uninstalled ipywidgets-7.7.1\n","Successfully installed addict-2.4.0 comm-0.2.1 configargparse-1.7 dash-2.16.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.2 jedi-0.19.1 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.10\n"]}]},{"cell_type":"code","source":["import os\n","path = '/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program'\n","\n","#作業ディレクトリをpathに移動する\n","os.chdir(path)\n","\n","#作業ディレクトリ直下のファイルを確認\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0MMEVluju39","executionInfo":{"status":"ok","timestamp":1709620853642,"user_tz":-540,"elapsed":1781,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}},"outputId":"466e9434-d82e-46e4-d65e-d3049d1976d1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["calculate.py\t\t      pretrained\t\t       TNUTEJN016.pcd\n","checkpoint\t\t      __pycache__\t\t       Tokuichi_divide.py\n","data_list_key_0.csv\t      Registration_test_jurai_ptlk.py  T-pipe_matching.py\n","data_list_key_90.csv\t      Registration_test_jurai.py       T-pipe_test_jurai_ptlk.py\n","data_list_key_L_180.csv       Registration_test.py\t       Tpipe_test_jurai_ptlk_time.ipynb\n","data_list_key_L_90.csv\t      S3DIS.py\t\t\t       T-pipe_test_jurai.py\n","data_list_proposed_0.csv      sensor_cheese_noise.pcd\t       Tpipe_test_jurai_time.ipynb\n","data_list_proposed_90.csv     sensor_Ljoint_180_2.pcd\t       T-pipe_test.py\n","data_list_proposed_L_180.csv  sensor_Ljoint_90_4.pcd\t       Tpipe_test_time.ipynb\n","data_list_proposed_L_90.csv   sensor_tpip_135_2.pcd\t       WMU2LR2020_half2.pcd\n","dataset.py\t\t      sensor_tpip_45_3.pcd\t       WMU2LR2020_half_unnoise.pcd\n","Global_optimizer.py\t      sensor_tpip_90_1.pcd\t       WMU2LR2020.pcd\n","learning3d\t\t      TNUTEJN016_half2.pcd\n","network.py\t\t      TNUTEJN016_half_unnoise.pcd\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import h5py\n","import subprocess\n","import shlex\n","import json\n","import glob\n","from sklearn.neighbors import NearestNeighbors\n","from scipy.spatial.distance import minkowski\n","from scipy.spatial import cKDTree\n","from scipy.spatial.transform import Rotation\n","from torch import sin, cos\n","import open3d as o3d\n","from tqdm import tqdm\n","import torchvision\n","import logging\n","import random\n","import os\n","import numpy.linalg as LA\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","import plotly.graph_objects as go\n","import copy\n","import time"],"metadata":{"id":"00Xhk8ZyjwoS","executionInfo":{"status":"ok","timestamp":1709620863970,"user_tz":-540,"elapsed":10333,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["############################################\n","# 位置合わせ描画\n","############################################\n","def draw_registration_result(source, target, transformation):\n","    source_temp = copy.deepcopy(source)\n","    target_temp = copy.deepcopy(target)\n","    source_temp.paint_uniform_color([1, 0.706, 0])\n","    target_temp.paint_uniform_color([0, 0.651, 0.929])\n","    source_temp.transform(transformation)\n","    o3d.visualization.draw_geometries([source_temp, target_temp])\n","\n","def prepare_dataset(voxel_size, target, source):\n","\n","    #draw_registration_result(source, target, np.identity(4))\n","\n","    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n","    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n","    return source, target, source_down, target_down, source_fpfh, target_fpfh\n"],"metadata":{"id":"VCmWdyZbjzM1","executionInfo":{"status":"ok","timestamp":1709620863970,"user_tz":-540,"elapsed":6,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","def rotation_matrix_to_euler_angles(R):\n","    # Extract angles using trigonometric relations\n","    roll = np.arctan2(-R[1, 2], R[2, 2])\n","    pitch = np.arctan2(-(R[0, 2]*np.cos(roll)), R[2, 2])\n","    yaw = np.arctan2(-R[0, 1], R[0, 0])\n","\n","    return np.array([roll, pitch, yaw])\n","\n","def coordinate_3d(axes, range_x, range_y, range_z, grid = True):\n","    axes.set_xlabel(\"x\", fontsize = 14)\n","    axes.set_ylabel(\"y\", fontsize = 14)\n","    axes.set_zlabel(\"z\", fontsize = 14)\n","    axes.set_xlim(range_x[0], range_x[1])\n","    axes.set_ylim(range_y[0], range_y[1])\n","    axes.set_zlim(range_z[0], range_z[1])\n","    if grid == True:\n","        axes.grid()\n","\n","def visual_vector_3d(axes, loc, vector, color = \"red\"):\n","    axes.quiver(loc[0], loc[1], loc[2],\n","              vector[0], vector[1], vector[2],\n","              color = color, lw=3)\n","\n","\n","###################\n","#Registration\n","###################\n","class PointNet(torch.nn.Module):\n","\tdef __init__(self, emb_dims=1024, input_shape=\"bnc\", use_bn=False, global_feat=True):\n","\t\t# emb_dims:\t\t\tEmbedding Dimensions for PointNet.\n","\t\t# input_shape:\t\tShape of Input Point Cloud (b: batch, n: no of points, c: channels)\n","\t\tsuper(PointNet, self).__init__()\n","\t\tif input_shape not in [\"bcn\", \"bnc\"]:\n","\t\t\traise ValueError(\"Allowed shapes are 'bcn' (batch * channels * num_in_points), 'bnc' \")\n","\t\tself.input_shape = input_shape\n","\t\tself.emb_dims = emb_dims\n","\t\tself.use_bn = use_bn\n","\t\tself.global_feat = global_feat\n","\t\tif not self.global_feat: self.pooling = Pooling('max')\n","\n","\t\tself.layers = self.create_structure()\n","\n","\tdef create_structure(self):\n","\t\tself.conv1 = torch.nn.Conv1d(3, 64, 1)\n","\t\tself.conv2 = torch.nn.Conv1d(64, 64, 1)\n","\t\tself.conv3 = torch.nn.Conv1d(64, 64, 1)\n","\t\tself.conv4 = torch.nn.Conv1d(64, 128, 1)\n","\t\tself.conv5 = torch.nn.Conv1d(128, self.emb_dims, 1)\n","\t\tself.relu = torch.nn.ReLU()\n","\n","\t\tif self.use_bn:\n","\t\t\tself.bn1 = torch.nn.BatchNorm1d(64)\n","\t\t\tself.bn2 = torch.nn.BatchNorm1d(64)\n","\t\t\tself.bn3 = torch.nn.BatchNorm1d(64)\n","\t\t\tself.bn4 = torch.nn.BatchNorm1d(128)\n","\t\t\tself.bn5 = torch.nn.BatchNorm1d(self.emb_dims)\n","\n","\t\tif self.use_bn:\n","\t\t\tlayers = [self.conv1, self.bn1, self.relu,\n","\t\t\t\t\t  self.conv2, self.bn2, self.relu,\n","\t\t\t\t\t  self.conv3, self.bn3, self.relu,\n","\t\t\t\t\t  self.conv4, self.bn4, self.relu,\n","\t\t\t\t\t  self.conv5, self.bn5, self.relu]\n","\t\telse:\n","\t\t\tlayers = [self.conv1, self.relu,\n","\t\t\t\t\t  self.conv2, self.relu,\n","\t\t\t\t\t  self.conv3, self.relu,\n","\t\t\t\t\t  self.conv4, self.relu,\n","\t\t\t\t\t  self.conv5, self.relu]\n","\t\treturn layers\n","\n","\n","\tdef forward(self, input_data):\n","\t\t# input_data: \t\tPoint Cloud having shape input_shape.\n","\t\t# output:\t\t\tPointNet features (Batch x emb_dims)\n","\t\tif self.input_shape == \"bnc\":\n","\t\t\tnum_points = input_data.shape[1]\n","\t\t\tinput_data = input_data.permute(0, 2, 1)\n","\t\telse:\n","\t\t\tnum_points = input_data.shape[2]\n","\t\tif input_data.shape[1] != 3:\n","\t\t\traise RuntimeError(\"shape of x must be of [Batch x 3 x NumInPoints]\")\n","\n","\t\toutput = input_data\n","\t\tfor idx, layer in enumerate(self.layers):\n","\t\t\toutput = layer(output)\n","\t\t\tif idx == 1 and not self.global_feat: point_feature = output\n","\n","\t\tif self.global_feat:\n","\t\t\treturn output\n","\t\telse:\n","\t\t\toutput = self.pooling(output)\n","\t\t\toutput = output.view(-1, self.emb_dims, 1).repeat(1, 1, num_points)\n","\t\t\treturn torch.cat([output, point_feature], 1)\n","\n","class Pooling(torch.nn.Module):\n","\tdef __init__(self, pool_type='max'):\n","\t\tself.pool_type = pool_type\n","\t\tsuper(Pooling, self).__init__()\n","\n","\tdef forward(self, input):\n","\t\tif self.pool_type == 'max':\n","\t\t\treturn torch.max(input, 2)[0].contiguous()\n","\t\telif self.pool_type == 'avg' or self.pool_type == 'average':\n","\t\t\treturn torch.mean(input, 2).contiguous()\n","\n","\n","def batch_inverse(x):\n","    \"\"\" M(n) -> M(n); x -> x^-1 \"\"\"\n","    batch_size, h, w = x.size()\n","    assert h == w\n","    y = torch.zeros_like(x)\n","    for i in range(batch_size):\n","        y[i, :, :] = x[i, :, :].inverse()\n","    return y\n","\n","def batch_inverse_dx(y):\n","    \"\"\" backward \"\"\"\n","    # Let y(x) = x^-1.\n","    # compute dy\n","    #   dy = dy(j,k)\n","    #      = - y(j,m) * dx(m,n) * y(n,k)\n","    #      = - y(j,m) * y(n,k) * dx(m,n)\n","    # therefore,\n","    #   dy(j,k)/dx(m,n) = - y(j,m) * y(n,k)\n","    batch_size, h, w = y.size()\n","    assert h == w\n","    # compute dy(j,k,m,n) = dy(j,k)/dx(m,n) = - y(j,m) * y(n,k)\n","    #   = - (y(j,:))' * y'(k,:)\n","    yl = y.repeat(1, 1, h).view(batch_size*h*h, h, 1)\n","    yr = y.transpose(1, 2).repeat(1, h, 1).view(batch_size*h*h, 1, h)\n","    dy = - yl.bmm(yr).view(batch_size, h, h, h, h)\n","\n","    # compute dy(m,n,j,k) = dy(j,k)/dx(m,n) = - y(j,m) * y(n,k)\n","    #   = - (y'(m,:))' * y(n,:)\n","    #yl = y.transpose(1, 2).repeat(1, 1, h).view(batch_size*h*h, h, 1)\n","    #yr = y.repeat(1, h, 1).view(batch_size*h*h, 1, h)\n","    #dy = - yl.bmm(yr).view(batch_size, h, h, h, h)\n","\n","    return dy\n","\n","class InvMatrix(torch.autograd.Function):\n","    \"\"\" M(n) -> M(n); x -> x^-1.\n","    \"\"\"\n","    @staticmethod\n","    def forward(ctx, x):\n","        y = batch_inverse(x)\n","        ctx.save_for_backward(y)\n","        return y\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        y, = ctx.saved_tensors   # v0.4\n","        #y, = ctx.saved_variables  # v0.3.1\n","        batch_size, h, w = y.size()\n","        assert h == w\n","\n","        # Let y(x) = x^-1 and assume any function f(y(x)).\n","        # compute df/dx(m,n)...\n","        #   df/dx(m,n) = df/dy(j,k) * dy(j,k)/dx(m,n)\n","        # well, df/dy is 'grad_output'\n","        # and so we will return 'grad_input = df/dy(j,k) * dy(j,k)/dx(m,n)'\n","\n","        dy = batch_inverse_dx(y)  # dy(j,k,m,n) = dy(j,k)/dx(m,n)\n","        go = grad_output.contiguous().view(batch_size, 1, h*h)  # [1, (j*k)]\n","        ym = dy.view(batch_size, h*h, h*h)  # [(j*k), (m*n)]\n","        r = go.bmm(ym)  # [1, (m*n)]\n","        grad_input = r.view(batch_size, h, h)  # [m, n]\n","\n","        return grad_input\n","\n","def sinc1(t):\n","    \"\"\" sinc1: t -> sin(t)/t \"\"\"\n","    e = 0.01\n","    r = torch.zeros_like(t)\n","    a = torch.abs(t)\n","\n","    s = a < e\n","    c = (s == 0)\n","    t2 = t[s] ** 2\n","    r[s] = 1 - t2/6*(1 - t2/20*(1 - t2/42))  # Taylor series O(t^8)\n","    r[c] = sin(t[c]) / t[c]\n","\n","    return r\n","\n","def sinc2(t):\n","    \"\"\" sinc2: t -> (1 - cos(t)) / (t**2) \"\"\"\n","    e = 0.01\n","    r = torch.zeros_like(t)\n","    a = torch.abs(t)\n","\n","    s = a < e\n","    c = (s == 0)\n","    t2 = t ** 2\n","    r[s] = 1/2*(1-t2[s]/12*(1-t2[s]/30*(1-t2[s]/56)))  # Taylor series O(t^8)\n","    r[c] = (1-cos(t[c]))/t2[c]\n","\n","    return r\n","\n","\n","def sinc3(t):\n","    \"\"\" sinc3: t -> (t - sin(t)) / (t**3) \"\"\"\n","    e = 0.01\n","    r = torch.zeros_like(t)\n","    a = torch.abs(t)\n","\n","    s = a < e\n","    c = (s == 0)\n","    t2 = t[s] ** 2\n","    r[s] = 1/6*(1-t2/20*(1-t2/42*(1-t2/72)))  # Taylor series O(t^8)\n","    r[c] = (t[c]-sin(t[c]))/(t[c]**3)\n","\n","    return r\n","\n","\n","def so3_mat(x):\n","    # size: [*, 3] -> [*, 3, 3]\n","    x_ = x.view(-1, 3)\n","    x1, x2, x3 = x_[:, 0], x_[:, 1], x_[:, 2]\n","    O = torch.zeros_like(x1)\n","\n","    X = torch.stack((\n","        torch.stack((O, -x3, x2), dim=1),\n","        torch.stack((x3, O, -x1), dim=1),\n","        torch.stack((-x2, x1, O), dim=1)), dim=1)\n","    return X.view(*(x.size()[0:-1]), 3, 3)\n","\n","def exp(x):\n","    x_ = x.view(-1, 6)\n","    w, v = x_[:, 0:3], x_[:, 3:6]\n","    t = w.norm(p=2, dim=1).view(-1, 1, 1)\n","    W = so3_mat(w)\n","    S = W.bmm(W)\n","    I = torch.eye(3).to(w)\n","\n","    # Rodrigues' rotation formula.\n","    #R = cos(t)*eye(3) + sinc1(t)*W + sinc2(t)*(w*w');\n","    #  = eye(3) + sinc1(t)*W + sinc2(t)*S\n","    R = I + sinc1(t)*W + sinc2(t)*S\n","\n","    #V = sinc1(t)*eye(3) + sinc2(t)*W + sinc3(t)*(w*w')\n","    #  = eye(3) + sinc2(t)*W + sinc3(t)*S\n","    V = I + sinc2(t)*W + sinc3(t)*S\n","\n","    p = V.bmm(v.contiguous().view(-1, 3, 1))\n","\n","    z = torch.Tensor([0, 0, 0, 1]).view(1, 1, 4).repeat(x_.size(0), 1, 1).to(x)\n","    Rp = torch.cat((R, p), dim=2)\n","    g = torch.cat((Rp, z), dim=1)\n","\n","    return g.view(*(x.size()[0:-1]), 4, 4)\n","\n","def mat(x):\n","    # size: [*, 6] -> [*, 4, 4]\n","    x_ = x.view(-1, 6)\n","    w1, w2, w3 = x_[:, 0], x_[:, 1], x_[:, 2]\n","    v1, v2, v3 = x_[:, 3], x_[:, 4], x_[:, 5]\n","    O = torch.zeros_like(w1)\n","\n","    X = torch.stack((\n","        torch.stack((  O, -w3,  w2, v1), dim=1),\n","        torch.stack(( w3,   O, -w1, v2), dim=1),\n","        torch.stack((-w2,  w1,   O, v3), dim=1),\n","        torch.stack((  O,   O,   O,  O), dim=1)), dim=1)\n","    return X.view(*(x.size()[0:-1]), 4, 4)\n","\n","def genvec():\n","    return torch.eye(6)\n","\n","def genmat():\n","    return mat(genvec())\n","\n","class ExpMap(torch.autograd.Function):\n","    \"\"\" Exp: se(3) -> SE(3)\n","    \"\"\"\n","    @staticmethod\n","    def forward(ctx, x):\n","        \"\"\" Exp: R^6 -> M(4),\n","            size: [B, 6] -> [B, 4, 4],\n","              or  [B, 1, 6] -> [B, 1, 4, 4]\n","        \"\"\"\n","        ctx.save_for_backward(x)\n","        g = exp(x)\n","        return g\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        x, = ctx.saved_tensors\n","        g = exp(x)\n","        gen_k = genmat().to(x)\n","\n","        # Let z = f(g) = f(exp(x))\n","        # dz = df/dgij * dgij/dxk * dxk\n","        #    = df/dgij * (d/dxk)[exp(x)]_ij * dxk\n","        #    = df/dgij * [gen_k*g]_ij * dxk\n","\n","        dg = gen_k.matmul(g.view(-1, 1, 4, 4))\n","        # (k, i, j)\n","        dg = dg.to(grad_output)\n","\n","        go = grad_output.contiguous().view(-1, 1, 4, 4)\n","        dd = go * dg\n","        grad_input = dd.sum(-1).sum(-1)\n","\n","        return grad_input\n","\n","def transform(g, a):\n","    # g : SE(3),  * x 4 x 4\n","    # a : R^3,    * x 3[x N]\n","    g_ = g.view(-1, 4, 4)\n","    R = g_[:, 0:3, 0:3].contiguous().view(*(g.size()[0:-2]), 3, 3)\n","    p = g_[:, 0:3, 3].contiguous().view(*(g.size()[0:-2]), 3)\n","    #print(\"g\")\n","    #print(g)\n","    #print(\"p\")\n","    #print(p)\n","    if len(g.size()) == len(a.size()):\n","        b = R.matmul(a) + p.unsqueeze(-1)\n","    else:\n","        b = R.matmul(a.unsqueeze(-1)).squeeze(-1) + p\n","    return b\n","\n","\n","def mean_shift(template, source, p0_zero_mean, p1_zero_mean):\n","\ttemplate_mean = torch.eye(3).view(1, 3, 3).expand(template.size(0), 3, 3).to(template) \t\t# [B, 3, 3]\n","\tsource_mean = torch.eye(3).view(1, 3, 3).expand(source.size(0), 3, 3).to(source) \t\t\t# [B, 3, 3]\n","\n","\tif p0_zero_mean:\n","\t\tp0_m = template.mean(dim=1) # [B, N, 3] -> [B, 3]\n","\t\ttemplate_mean = torch.cat([template_mean, p0_m.unsqueeze(-1)], dim=2)\n","\t\tone_ = torch.tensor([[[0.0, 0.0, 0.0, 1.0]]]).repeat(template_mean.shape[0], 1, 1).to(template_mean)    # (Bx1x4)\n","\t\ttemplate_mean = torch.cat([template_mean, one_], dim=1)\n","\t\ttemplate = template - p0_m.unsqueeze(1)\n","\t# else:\n","\t\t# q0 = template\n","\n","\tif p1_zero_mean:\n","\t\t#print(numpy.any(numpy.isnan(p1.numpy())))\n","\t\tp1_m = source.mean(dim=1) # [B, N, 3] -> [B, 3]\n","\t\tsource_mean = torch.cat([source_mean, -p1_m.unsqueeze(-1)], dim=2)\n","\t\tone_ = torch.tensor([[[0.0, 0.0, 0.0, 1.0]]]).repeat(source_mean.shape[0], 1, 1).to(source_mean)    # (Bx1x4)\n","\t\tsource_mean = torch.cat([source_mean, one_], dim=1)\n","\t\tsource = source - p1_m.unsqueeze(1)\n","\t# else:\n","\t\t# q1 = source\n","\treturn template, source, template_mean, source_mean\n","\n","def postprocess_data(result, p0, p1, a0, a1, p0_zero_mean, p1_zero_mean):\n","\t#output' = trans(p0_m) * output * trans(-p1_m)\n","\t#        = [I, p0_m;] * [R, t;] * [I, -p1_m;]\n","\t#          [0, 1    ]   [0, 1 ]   [0,  1    ]\n","\test_g = result['est_T']\n","\tif p0_zero_mean:\n","\t\test_g = a0.to(est_g).bmm(est_g)\n","\tif p1_zero_mean:\n","\t\test_g = est_g.bmm(a1.to(est_g))\n","\tresult['est_T'] = est_g\n","\n","\test_gs = result['est_T_series'] # [M, B, 4, 4]\n","\tif p0_zero_mean:\n","\t\test_gs = a0.unsqueeze(0).contiguous().to(est_gs).matmul(est_gs)\n","\tif p1_zero_mean:\n","\t\test_gs = est_gs.matmul(a1.unsqueeze(0).contiguous().to(est_gs))\n","\tresult['est_T_series'] = est_gs\n","\n","\treturn result\n","\n","class PointNetLK(nn.Module):\n","\tdef __init__(self, feature_model=PointNet(), delta=1.0e-2, learn_delta=False, xtol=1.0e-7, p0_zero_mean=True, p1_zero_mean=True, pooling='max'):\n","\t\tsuper().__init__()\n","\t\tself.feature_model = feature_model\n","\t\tself.pooling = Pooling(pooling)\n","\t\tself.inverse = InvMatrix.apply\n","\t\tself.exp = ExpMap.apply # [B, 6] -> [B, 4, 4]\n","\t\tself.transform = transform # [B, 1, 4, 4] x [B, N, 3] -> [B, N, 3]\n","\n","\t\tw1, w2, w3, v1, v2, v3 = delta, delta, delta, delta, delta, delta\n","\t\ttwist = torch.Tensor([w1, w2, w3, v1, v2, v3])\n","\t\tself.dt = torch.nn.Parameter(twist.view(1, 6), requires_grad=learn_delta)\n","\n","\t\t# results\n","\t\tself.last_err = None\n","\t\tself.g_series = None # for debug purpose\n","\t\tself.prev_r = None\n","\t\tself.g = None # estimation result\n","\t\tself.itr = 0\n","\t\tself.xtol = xtol\n","\t\tself.p0_zero_mean = p0_zero_mean\n","\t\tself.p1_zero_mean = p1_zero_mean\n","\n","\tdef forward(self, template, source, maxiter=100):\n","\t\ttemplate, source, template_mean, source_mean = mean_shift(template, source, self.p0_zero_mean, self.p1_zero_mean)\n","\n","\t\tresult = self.iclk(template, source, maxiter)\n","\t\tresult = postprocess_data(result, template, source, template_mean, source_mean, self.p0_zero_mean, self.p1_zero_mean)\n","\t\treturn result\n","\n","\tdef iclk(self, template, source, maxiter):\n","\t\tbatch_size = template.size(0)\n","\n","\t\test_T0 = torch.eye(4).to(template).view(1, 4, 4).expand(template.size(0), 4, 4).contiguous()\n","\t\test_T = est_T0\n","\t\tself.est_T_series = torch.zeros(maxiter+1, *est_T0.size(), dtype=est_T0.dtype)\n","\t\tself.est_T_series[0] = est_T0.clone()\n","\n","\t\ttraining = self.handle_batchNorm(template, source)\n","\n","\t\t# re-calc. with current modules\n","\t\ttemplate_features = self.pooling(self.feature_model(template)) # [B, N, 3] -> [B, K]\n","\n","\t\t# approx. J by finite difference\n","\t\tdt = self.dt.to(template).expand(batch_size, 6)\n","\t\tJ = self.approx_Jic(template, template_features, dt)\n","\t\tself.last_err = None\n","\t\tpinv = self.compute_inverse_jacobian(J, template_features, source)\n","\n","\t\tif pinv == {}:\n","\t\t\tresult = {'est_R': est_T[:,0:3,0:3],\n","\t\t\t\t\t  'est_t': est_T[:,0:3,3],\n","\t\t\t\t\t  'est_T': est_T,\n","\t\t\t\t\t  'r': None,\n","\t\t\t\t\t  'transformed_source': self.transform(est_T.unsqueeze(1), source),\n","\t\t\t\t\t  'itr': 1,\n","\t\t\t\t\t  'est_T_series': self.est_T_series}\n","\t\t\treturn result\n","\n","\t\titr = 0\n","\t\tr = None\n","\t\tfor itr in range(maxiter):\n","\t\t\tself.prev_r = r\n","\t\t\ttransformed_source = self.transform(est_T.unsqueeze(1), source) # [B, 1, 4, 4] x [B, N, 3] -> [B, N, 3]\n","\t\t\tsource_features = self.pooling(self.feature_model(transformed_source)) # [B, N, 3] -> [B, K]\n","\t\t\tr = source_features - template_features\n","\n","\t\t\tpose = -pinv.bmm(r.unsqueeze(-1)).view(batch_size, 6)\n","\n","\t\t\tcheck = pose.norm(p=2, dim=1, keepdim=True).max()\n","\t\t\tif float(check) < self.xtol:\n","\t\t\t\tif itr == 0:\n","\t\t\t\t\tself.last_err = 0 # no update.\n","\t\t\t\tbreak\n","\n","\t\t\test_T = self.update(est_T, pose)\n","\t\t\tself.est_T_series[itr+1] = est_T.clone()\n","\n","\t\trep = len(range(itr, maxiter))\n","\t\tself.est_T_series[(itr+1):] = est_T.clone().unsqueeze(0).repeat(rep, 1, 1, 1)\n","\n","\t\tself.feature_model.train(training)\n","\t\tself.est_T = est_T\n","\n","\t\t#print(\"est_T.unsqueeze(1)\")\n","\t\t#print(est_T.unsqueeze(1))\n","\t\tresult = {'est_R': est_T[:,0:3,0:3],\n","\t\t\t\t  'est_t': est_T[:,0:3,3],\n","\t\t\t\t  'est_T': est_T,\n","\t\t\t\t  'r': r,\n","\t\t\t\t  'transformed_source': self.transform(est_T.unsqueeze(1), source),\n","\t\t\t\t  'itr': itr+1,\n","\t\t\t\t  'est_T_series': self.est_T_series}\n","\n","\t\treturn result\n","\n","\tdef update(self, g, dx):\n","\t\t# [B, 4, 4] x [B, 6] -> [B, 4, 4]\n","\t\tdg = self.exp(dx)\n","\t\treturn dg.matmul(g)\n","\n","\tdef approx_Jic(self, template, template_features, dt):\n","\t\t# p0: [B, N, 3], Variable\n","\t\t# f0: [B, K], corresponding feature vector\n","\t\t# dt: [B, 6], Variable\n","\t\t# Jk = (feature_model(p(-delta[k], p0)) - f0) / delta[k]\n","\n","\t\tbatch_size = template.size(0)\n","\t\tnum_points = template.size(1)\n","\n","\t\t# compute transforms\n","\t\ttransf = torch.zeros(batch_size, 6, 4, 4).to(template)\n","\t\tfor b in range(template.size(0)):\n","\t\t\td = torch.diag(dt[b, :]) # [6, 6]\n","\t\t\tD = self.exp(-d) # [6, 4, 4]\n","\t\t\ttransf[b, :, :, :] = D[:, :, :]\n","\t\ttransf = transf.unsqueeze(2).contiguous()  #   [B, 6, 1, 4, 4]\n","\t\tp = self.transform(transf, template.unsqueeze(1)) # x [B, 1, N, 3] -> [B, 6, N, 3]\n","\n","\t\t#f0 = self.feature_model(p0).unsqueeze(-1) # [B, K, 1]\n","\t\ttemplate_features = template_features.unsqueeze(-1) # [B, K, 1]\n","\t\tf = self.pooling(self.feature_model(p.view(-1, num_points, 3))).view(batch_size, 6, -1).transpose(1, 2) # [B, K, 6]\n","\n","\t\tdf = template_features - f # [B, K, 6]\n","\t\tJ = df / dt.unsqueeze(1)\n","\n","\t\treturn J\n","\n","\tdef compute_inverse_jacobian(self, J, template_features, source):\n","\t\t# compute pinv(J) to solve J*x = -r\n","\t\ttry:\n","\t\t\tJt = J.transpose(1, 2) # [B, 6, K]\n","\t\t\tH = Jt.bmm(J) # [B, 6, 6]\n","\t\t\tB = self.inverse(H)\n","\t\t\tpinv = B.bmm(Jt) # [B, 6, K]\n","\t\t\treturn pinv\n","\t\texcept RuntimeError as err:\n","\t\t\t# singular...?\n","\t\t\tself.last_err = err\n","\t\t\tg = torch.eye(4).to(source).view(1, 4, 4).expand(source.size(0), 4, 4).contiguous()\n","\t\t\t#print(err)\n","\t\t\t# Perhaps we can use MP-inverse, but,...\n","\t\t\t# probably, self.dt is way too small...\n","\t\t\tsource_features = self.pooling(self.feature_model(source)) # [B, N, 3] -> [B, K]\n","\t\t\tr = source_features - template_features\n","\t\t\tself.feature_model.train(self.feature_model.training)\n","\t\t\treturn {}\n","\n","\tdef handle_batchNorm(self, template, source):\n","\t\ttraining = self.feature_model.training\n","\t\tif training:\n","\t\t\t# first, update BatchNorm modules\n","\t\t\ttemplate_features, source_features = self.pooling(self.feature_model(template)), self.pooling(self.feature_model(source))\n","\t\tself.feature_model.eval()\t# and fix them.\n","\t\treturn training\n","\n","def rotation_matrix_to_euler_angles(R):\n","    \"\"\"\n","    Convert a 3x3 rotation matrix to Euler angles.\n","\n","    Parameters:\n","        R (numpy.ndarray): 3x3 rotation matrix.\n","\n","    Returns:\n","        numpy.ndarray: Euler angles [roll, pitch, yaw] in radians.\n","    \"\"\"\n","    # Extract angles using trigonometric relations\n","    roll = np.arctan2(R[2, 1], R[2, 2])\n","    pitch = np.arctan2(-R[2, 0], np.sqrt(R[2, 1]**2 + R[2, 2]**2))\n","    yaw = np.arctan2(R[1, 0], R[0, 0])\n","\n","    return np.array([roll, pitch, yaw])\n","\n","def coordinate_3d(axes, range_x, range_y, range_z, grid = True):\n","    axes.set_xlabel(\"x\", fontsize = 14)\n","    axes.set_ylabel(\"y\", fontsize = 14)\n","    axes.set_zlabel(\"z\", fontsize = 14)\n","    axes.set_xlim(range_x[0], range_x[1])\n","    axes.set_ylim(range_y[0], range_y[1])\n","    axes.set_zlim(range_z[0], range_z[1])\n","    if grid == True:\n","        axes.grid()\n","\n","def visual_vector_3d(axes, loc, vector, color = \"red\"):\n","    axes.quiver(loc[0], loc[1], loc[2],\n","              vector[0], vector[1], vector[2],\n","              color = color, lw=3)\n","\n","\n","###################\n","#Registration\n","###################\n","# Define Registration Algorithm.\n","def registration_algorithm(device=torch.device('cpu')):\n","\n","  #reg_algorithm = ICP()\n","\n","  pretrained_reg = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/pretrained/best_model.t7\"\n","\n","  ptnet = PointNet(emb_dims=1024, input_shape=\"bnc\", use_bn=True, global_feat=True)\n","  pnlk = PointNetLK(feature_model=ptnet, delta=1.0e-2, learn_delta=False, xtol=1.0e-7, p0_zero_mean=True, p1_zero_mean=True, pooling='max')\n","  if pretrained_reg:\n","      assert os.path.isfile(pretrained_reg)\n","      pnlk.load_state_dict(torch.load(pretrained_reg, map_location='cpu'))\n","      #print(\"PointNetLK pretrained model loaded successfully!\")\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  pnlk = pnlk.to(device)\n","  reg_algorithm = pnlk\n","\n","  return reg_algorithm\n","\n","\n","# Register template and source pairs.\n","class Registration:\n","\tdef __init__(self):\n","\t\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\t\tself.reg_algorithm = registration_algorithm(device)\n","\n","\t@staticmethod\n","\tdef pc2points(data):\n","\t\tif len(data.shape) == 3:\n","\t\t\treturn data[:, :, :3]\n","\t\telif len(data.shape) == 2:\n","\t\t\treturn data[:, :3]\n","\n","\tdef register(self, template, source, start):\n","\t\t# template, source: \t\tPoint Cloud [B, N, 3] (torch tensor)\n","\n","\t\t# No need to use normals. Only use normals for RPM-Net.\n","\t\t#if not self.is_rpmnet == 'rpmnet':\n","\t\t#\ttemplate, source = self.pc2points(template), self.pc2points(source)\n","\n","\t\tresult = self.reg_algorithm(template, source)\n","\t\treturn result\n","\n","def pc2open3d(data):\n","\tif torch.is_tensor(data): data = data.detach().cpu().numpy()\n","\tif len(data.shape) == 2:\n","\t\tpc = o3d.geometry.PointCloud()\n","\t\tpc.points = o3d.utility.Vector3dVector(data)\n","\t\treturn pc\n","\telse:\n","\t\tprint(\"Error in the shape of data given to Open3D!, Shape is \", data.shape)\n","\n","\n","def display_results_sample(template, source, est_T, masked_template, transformed_source):\n","  transformed_source = np.matmul(est_T[0:3, 0:3], source.T).T + est_T[0:3, 3]     # ※matmul：行列の積　　第一項：回転、第二項：平行移動\n","\n","  ### x軸の表示 ###\n","  numpy_ax_x = np.array([[0.01, 0, 0], [0.02, 0, 0], [0.03, 0, 0], [0.04, 0, 0], [0.05, 0, 0], [0.06, 0, 0], [0.07, 0, 0], [0.08, 0, 0], [0.09, 0, 0], [0.1, 0, 0]])\n","  ax_x = o3d.geometry.PointCloud()\n","  ax_x.points = o3d.utility.Vector3dVector(numpy_ax_x)\n","  ax_x.paint_uniform_color([1/3, 1/3, 1/3])\n","\n","  ### y軸の表示 ###\n","  numpy_ax_y = np.array([[0, 0.01, 0], [0, 0.02, 0], [0, 0.03, 0], [0, 0.04, 0], [0, 0.05, 0], [0, 0.06, 0], [0, 0.07, 0], [0, 0.08, 0], [0, 0.09, 0], [0, 0.1, 0]])\n","  ax_y = o3d.geometry.PointCloud()\n","  ax_y.points = o3d.utility.Vector3dVector(numpy_ax_y)\n","  ax_y.paint_uniform_color([1/3, 1/3, 1/3])\n","\n","  ### z軸の表示 ###\n","  numpy_ax_z = np.array([[0, 0, 0.01], [0, 0, 0.02], [0, 0, 0.03], [0, 0, 0.04], [0, 0, 0.05], [0, 0, 0.06], [0, 0, 0.07], [0, 0, 0.08], [0, 0, 0.09], [0, 0, 0.1]])\n","  ax_z = o3d.geometry.PointCloud()\n","  ax_z.points = o3d.utility.Vector3dVector(numpy_ax_z)\n","  ax_z.paint_uniform_color([1/3, 1/3, 1/3])\n","\n","  ### 原点を表示 ###\n","  numpy_o = np.array([[0, 0, 0]])\n","  o = o3d.geometry.PointCloud()\n","  o.points = o3d.utility.Vector3dVector(numpy_o)\n","  o.paint_uniform_color([1, 0, 0])\n","\n","  ### 正解を定義 ###\n","  if theta == 0:\n","  \t## 0度 ##\n","  \tans_theta_x = np.radians(0)\n","  \tans_theta_y = np.radians(1)\n","  \tans_theta_z = np.radians(-184)\n","  elif theta == 45:\n","  \t## 90度 ##\n","  \tans_theta_x = np.radians(2)\n","  \tans_theta_y = np.radians(0.2)\n","  \tans_theta_z = np.radians(-135)\n","  elif theta == 90:\n","  \t## 90度 ##\n","  \tans_theta_x = np.radians(2)\n","  \tans_theta_y = np.radians(0.2)\n","  \tans_theta_z = np.radians(-90)\n","  elif theta == 135:\n","  \t## 90度 ##\n","  \tans_theta_x = np.radians(2)\n","  \tans_theta_y = np.radians(0.2)\n","  \tans_theta_z = np.radians(-45)\n","  elif theta == \"L_90\":\n","  \t## 90度 ##\n","  \tans_theta_x = np.radians(-3)\n","  \tans_theta_y = np.radians(-1)\n","  \tans_theta_z = np.radians(-85)\n","  elif theta == \"L_180\":\n","  \t## 90度 ##\n","  \tans_theta_x = np.radians(-12)\n","  \tans_theta_y = np.radians(-2)\n","  \tans_theta_z = np.radians(176)\n","  # x軸方向に回転\n","  R_x = np.array(\n","         [[1, 0, 0],\n","         [0, np.cos(ans_theta_x), -np.sin(ans_theta_x)],\n","         [0, np.sin(ans_theta_x), np.cos(ans_theta_x)]])\n","  # y軸方向に回転\n","  R_y = np.array(\n","         [[np.cos(ans_theta_y), 0, np.sin(ans_theta_y)],\n","         [0, 1, 0],\n","         [-np.sin(ans_theta_y), 0, np.cos(ans_theta_y)]])\n","  # z軸方向に回転\n","  R_z = np.array(\n","         [[np.cos(ans_theta_z), -np.sin(ans_theta_z), 0],\n","         [np.sin(ans_theta_z), np.cos(ans_theta_z), 0],\n","         [0, 0, 1]])\n","\n","  # 回転行列を計算\n","  ans_R = R_x @ R_y @ R_z\n","  print(\"ans_R:\\n\", ans_R)\n","  print(\"est_R:\\n\", est_T[0:3, 0:3])\n","  # 平行移動\n","  ans_t_ = [0, 0.008, -0.011]\n","  if theta == \"L_90\":\n","\n","  \tans_t_ = [0.0055, 0.008, -0.011]\n","  if theta == \"L_180\":\n","\n","  \tans_t_ = [0.006, 0.008, -0.011]\n","\n","  # 重心移動も含めた変換を行う\n","  ans_t = np.matmul(ans_R, -np.mean(source, axis=0).T).T + ans_t_\n","  numpy_ans_source = np.matmul(ans_R, source.T).T + ans_t\n","  ans_source = o3d.geometry.PointCloud()\n","  ans_source.points = o3d.utility.Vector3dVector(numpy_ans_source)\n","\n","  ### 回転移動の差分 ###\n","  euler_angles = rotation_matrix_to_euler_angles(est_T[0:3, 0:3])\n","  rotation_angle_x = np.degrees(euler_angles[0])\n","  rotation_angle_y = np.degrees(euler_angles[1])\n","  rotation_angle_z = np.degrees(euler_angles[2])\n","  print(\"\\nRotation angle around x-axis:\", rotation_angle_x, \"degrees\")\n","  print(\"Rotation angle around y-axis:\", rotation_angle_y, \"degrees\")\n","  print(\"Rotation angle around z-axis:\", rotation_angle_z, \"degrees\")\n","  ###print(\"\\n回転移動の差：\")\n","  diff_R_x = rotation_angle_x - np.degrees(ans_theta_x)\n","  diff_R_y = rotation_angle_y - np.degrees(ans_theta_y)\n","  diff_R_z = rotation_angle_z - np.degrees(ans_theta_z)\n","  ###print(\"x軸方向　\", abs(diff_R_x), \" \", \"y軸方向　\", abs(diff_R_y), \" \", \"z軸方向　\", abs(diff_R_z))\n","  global diff_R\n","  diff_R = np.linalg.norm([diff_R_x, diff_R_y, diff_R_z])\n","  print(\"\\n回転移動の差（L2ノルム）：\", diff_R)\n","\n","  ### 平行移動の差分 ###\n","  global diff_t\n","  diff_t = np.linalg.norm(est_T[0:3, 3] - ans_t)\n","  print(\"平行移動の差（L2ノルム）：\", diff_t, \"\\n\")\n","  print(est_T[0:3, 3])\n","  print(ans_t )\n","\n","  template = pc2open3d(template)\n","  source = pc2open3d(source)\n","  #transformed_source = copy.deepcopy(source)\n","  #transformed_source.transform(est_T)\n","  transformed_source = pc2open3d(np.array(transformed_source))\n","  masked_template = pc2open3d(masked_template)\n","\n","  template.paint_uniform_color([1, 0, 0])\n","  source.paint_uniform_color([0, 1, 0])\n","  transformed_source.paint_uniform_color([0, 1, 0])\n","  masked_template.paint_uniform_color([0, 0, 1])\n","  ans_source.paint_uniform_color([1/3, 1/3, 1/3])\n","\n","  #o3d.visualization.draw_geometries([template])                                    # テンプレ\n","  o3d.visualization.draw_geometries([masked_template, source, ans_source])          # マスクテンプレ、ソース、正解ソース、原点\n","  #o3d.visualization.draw_geometries([masked_template, source, source_t, o, ax_x, ax_y, ax_z])\n","  #o3d.visualization.draw_geometries([masked_template, source, transformed_source])  # マスクテンプレ、ソース、変換後ソース\n","  o3d.visualization.draw_geometries([template, source, transformed_source, o])        # テンプレ、ソース、変換後ソース\n","  #o3d.visualization.draw_geometries([template, masked_template, source])           # テンプレ、マスクテンプレ、ソース\n","  #o3d.visualization.draw_geometries([template, source])                            # テンプレ、ソース\n","  #o3d.visualization.draw_geometries([masked_template, source])                     # マスクテンプレ、ソース\n","  ###masked_template.paint_uniform_color([0, 1, 0])\n","  ###o3d.visualization.draw_geometries([masked_template, source])                     # マスクテンプレ（green）"],"metadata":{"id":"17LZ04G-j1wG","executionInfo":{"status":"ok","timestamp":1709625631399,"user_tz":-540,"elapsed":791,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["theta = \"L_180\"\n","\n","# モデルのロード\n","save_path = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/checkpoint/model_weight_epoch300_batchsize32_plane.pth\"\n","model_load = torch.load(save_path)\n","\n","# テンプレートデータのロード\n","pcd_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/TNUTEJN016_half_unnoise.pcd\"\n","# ソースデータのロード\n","if theta == 0:   ## 0度 ##\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_cheese_noise.pcd\"\n","elif theta == 45:   ## 45度 ##\n","\tpass\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_tpip_45_3.pcd\"\n","elif theta == 90:   ## 90度 ##\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_tpip_90_1.pcd\"\n","elif theta == 135:   ## 135度 ##\n","\tpass\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_tpip_135_2.pcd\"\n","elif theta == \"L_90\":   ## L90 ##\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_Ljoint_90_4.pcd\"\n","\tpcd_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/TNUTEJN016_half_unnoise.pcd\"\n","elif theta == \"L_180\":   ## L180 ##\n","\tpcd_rot_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/sensor_Ljoint_180_2.pcd\"\n","\tpcd_file = \"/content/drive/MyDrive/ColabNotebooks/research/M1_object_detection/論文資料/program/TNUTEJN016_half_unnoise.pcd\"\n","\n","# テンプレとソースを点群データに変換\n","pcd_cheese = o3d.io.read_point_cloud(pcd_file)\n","pcd_cheese_rot = o3d.io.read_point_cloud(pcd_rot_file)\n","\n","numpy_cheese_points = np.array(pcd_cheese.points)\n","numpy_cheese_rot_points = np.array(pcd_cheese_rot.points)\n","\n","n = 1000\n","list_time1 = []\n","list_time2 = []\n","list_time3 = []\n","list_timeF = []\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","#model_load.to(device)\n","\n","\n","for i in range(n):\n","  #####計測開始#####\n","  torch.cuda.synchronize()\n","  start = time.time()\n","\n","  template_cheese = torch.tensor(numpy_cheese_points, dtype=torch.float32).unsqueeze(0)\n","  source_cheese = torch.tensor(numpy_cheese_rot_points, dtype=torch.float32).unsqueeze(0)\n","  template_cheese = template_cheese.to(device)\n","  source_cheese = source_cheese.to(device)\n","\n","  # 位置合わせ準備を行う（関数を呼び出す）\n","  registration_model = Registration()\n","\n","  #with torch.no_grad():\n","  #  masked_template_cheese, predicted_mask_cheese = model_load(template_cheese, source_cheese)\n","\n","\t# 提案手法（MaskNet、SVD、ICP）の実行（実際のデータを代入）\n","  result_cheese = registration_model.register(template_cheese, source_cheese, start)\n","  est_T_cheese = result_cheese['est_T']     # est_T：ICPの変換行列\n","\n","  #####計測終了#####\n","  torch.cuda.synchronize()\n","  elapsed_time_F = time.time() - start\n","  list_timeF.append(elapsed_time_F)\n","\n","time_meanF = sum(list_timeF) / len(list_timeF)\n"],"metadata":{"id":"TwqOC8v6qa6t","executionInfo":{"status":"ok","timestamp":1709627318809,"user_tz":-540,"elapsed":505260,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["time_meanF"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqpo3fTTNFoL","executionInfo":{"status":"ok","timestamp":1709627425301,"user_tz":-540,"elapsed":505,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}},"outputId":"1d65f656-5080-4638-d9ca-819e7a489466"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5046221380233764"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["import csv\n","def save_list_to_csv(filename, data):\n","    with open(filename, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Data'])\n","        for item in data:\n","            writer.writerow([item])\n","# リストの中身をCSVファイルに保存\n","save_list_to_csv(f'data_list_ptlk_{theta}.csv', list_timeF)"],"metadata":{"id":"djh1JYdmV2rJ","executionInfo":{"status":"ok","timestamp":1709627427490,"user_tz":-540,"elapsed":1,"user":{"displayName":"岩井悠","userId":"09259523131141906513"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_k0fpSC0iiOm"},"execution_count":null,"outputs":[]}]}